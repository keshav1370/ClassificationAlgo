{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_A1_NaiveBayesClassifier.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "G544Wl7oveg5"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import string\r\n",
        "import random"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fdQ7E4exX66"
      },
      "source": [
        "def load_doc(filename):\r\n",
        "    # open the file under read mode\r\n",
        "    file = open(filename, 'r')\r\n",
        "    content = file.read()\r\n",
        "    file.close()\r\n",
        "    return content\r\n",
        "\r\n",
        "# Split into sentences from content as every sentence is separated by a newline character\r\n",
        "def sentence(content):\r\n",
        "    sentences = []\r\n",
        "    sentences = list(content.split(\"\\n\"))\r\n",
        "    return sentences\r\n",
        "    \r\n",
        "\r\n",
        "# Load the document\r\n",
        "name = 'dataset_NB.txt'\r\n",
        "content = load_doc(name)\r\n",
        "sentences = sentence(content)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_F8NyVLx_Pj"
      },
      "source": [
        "# Text preprocessing\r\n",
        "lower_case_sentences = []\r\n",
        "for i in sentences:\r\n",
        "    lower_case_sentences.append(i.lower())\r\n",
        "\r\n",
        "without_punctuations = []\r\n",
        "for i in lower_case_sentences:\r\n",
        "    without_punctuations.append(''.join(c for c in i if c not in string.punctuation))\r\n",
        "\r\n",
        "clean_data = []\r\n",
        "for i in without_punctuations:\r\n",
        "    sub = i.split(',')\r\n",
        "    sub1 = [sub[0][0:len(sub)-2].rstrip(),sub[0][-1]]\r\n",
        "    clean_data.append(sub1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Z4qOM7y-yJwG",
        "outputId": "a4cff6ee-da4a-4200-eb0d-774f6a48eeb1"
      },
      "source": [
        "df = pd.DataFrame(clean_data, columns =['Statement', 'Sentiment'])\r\n",
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Statement</th>\n",
              "      <th>Sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>so there is no way for me to plug it in here i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>good case excellent value</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>great for the jawbone</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tied to charger for conversations lasting more...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the mic is great</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           Statement Sentiment\n",
              "0  so there is no way for me to plug it in here i...         0\n",
              "1                          good case excellent value         1\n",
              "2                              great for the jawbone         1\n",
              "3  tied to charger for conversations lasting more...         0\n",
              "4                                   the mic is great         1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCUWzD1yMVj"
      },
      "source": [
        "# Creating a list to store the F-score and accuracy for each fold iterations\r\n",
        "accur_values = []\r\n",
        "count_total = 0\r\n",
        "\r\n",
        "# Split a dataset into 7 folds\r\n",
        "def cross_validation(df, n_folds):\r\n",
        "    df_split = list()\r\n",
        "    df_copy = list(df)\r\n",
        "    fold_size = int(len(df) / 7)\r\n",
        "    for i in range (n_folds):\r\n",
        "        fold = []\r\n",
        "        while len(fold) < fold_size:\r\n",
        "            index = random.randrange(0,len(df_copy))\r\n",
        "            fold.append(df_copy.pop(index))\r\n",
        "        df_split.append(fold)\r\n",
        "    return df_split\r\n",
        "\r\n",
        "# Building vocabulary of model\r\n",
        "def words_frequency(train_df):\r\n",
        "    train_sentences = train_df['Statement'].values\r\n",
        "    train_sentences_list = train_sentences.tolist()\r\n",
        "    all_words_train = []\r\n",
        "    for i in train_sentences_list:\r\n",
        "        all_words_train.extend(i.split(' '))\r\n",
        "    vocab,count = np.unique(np.array(all_words_train),return_counts=True)\r\n",
        "    return (vocab,count)\r\n",
        "\r\n",
        "# Calculating likelihood probability P(d|C)\r\n",
        "# Writing a function for a given class C = 1,0\r\n",
        "def posterior_prob(train_df,vocab,count,words_test,prob_class, class_count):\r\n",
        "    posterior_prob = list()\r\n",
        "    #Calculations for test data in row i\r\n",
        "    for i in words_test:\r\n",
        "        likelihood_prob = 1\r\n",
        "        word_test_array = np.array(i)\r\n",
        "        vocab_test,count_test = np.unique(word_test_array,return_counts=True)\r\n",
        "        #j returns the elements of the iterable list i\r\n",
        "        for j in i:\r\n",
        "            try:\r\n",
        "                index = list(vocab).index(j)\r\n",
        "                # Here likelihood probability is returned for the ith row of test data\r\n",
        "                likelihood_prob *= ((count[index] + 1) / (np.sum(count) + np.sum(count_total) + 1))\r\n",
        "            except ValueError:\r\n",
        "                likelihood_prob *= ((0 + 1) / (np.sum(count) + np.sum(count_total) + 1))\r\n",
        "            \r\n",
        "        # Return the probability P(d|C)*P(C)\r\n",
        "        posterior = prob_class*likelihood_prob\r\n",
        "        posterior_prob.append(posterior)\r\n",
        "    return posterior_prob\r\n",
        "\r\n",
        "\r\n",
        "def accuracy_metric(actual, predicted):\r\n",
        "    correct = 0\r\n",
        "    for i in range(len(actual)):\r\n",
        "        if actual[i] == predicted[i]:\r\n",
        "            correct += 1\r\n",
        "    return correct / float(len(actual)) * 100.0\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7CfnsQ1HNSb",
        "outputId": "95964c81-5e56-4264-c900-ab019bffa848"
      },
      "source": [
        "def Naive_Bayes(train_set,test_set):\r\n",
        "    train_df = pd.DataFrame(train_set, columns =['Statement', 'Sentiment'])\r\n",
        "    test_df = pd.DataFrame(test_set,columns =['Statement', 'Sentiment'])\r\n",
        "    train_df_positive = train_df.loc[train_df['Sentiment']=='1']\r\n",
        "    train_df_negative = train_df.loc[train_df['Sentiment']=='0']\r\n",
        "\r\n",
        "\r\n",
        "    #Setting the positive sentiment and negative sentiment vocab and frequency\r\n",
        "    vocab_positive, count_positive = words_frequency(train_df_positive)\r\n",
        "    vocab_negative, count_negative = words_frequency(train_df_negative)\r\n",
        "    vocab_total, count_total = words_frequency(train_df)\r\n",
        "\r\n",
        "\r\n",
        "    #Gives the probability P(C) or prior probability\r\n",
        "    # no. of sentiment values is the same as the no. of reviews in train_set\r\n",
        "    train_sentiments = train_df['Sentiment'].values\r\n",
        "    sentiment,count = np.unique(train_sentiments,return_counts = True)\r\n",
        "\r\n",
        "    positive_review_count = count[1]\r\n",
        "    negative_review_count = count[0]\r\n",
        "\r\n",
        "    prob_positive = positive_review_count / (positive_review_count + negative_review_count)\r\n",
        "    prob_negative = negative_review_count / (positive_review_count + negative_review_count)\r\n",
        "\r\n",
        "    # extracting the words from the test_set\r\n",
        "    test_sentences = test_df['Statement'].values\r\n",
        "    test_sentences_list = test_sentences.tolist()\r\n",
        "    words_test = []\r\n",
        "    for i in test_sentences_list:\r\n",
        "        words_test.append(i.split(' '))\r\n",
        "\r\n",
        "\r\n",
        "            \r\n",
        "    posterior_prob_positive = posterior_prob(train_df,vocab_positive,count_positive,words_test,prob_positive,positive_review_count)\r\n",
        "    posterior_prob_negative = posterior_prob(train_df,vocab_negative,count_negative,words_test,prob_negative,negative_review_count)\r\n",
        "\r\n",
        "    test_predict = list()\r\n",
        "\r\n",
        "    #predict the Sentiment\r\n",
        "    for i in range (len(test_set)):\r\n",
        "        if posterior_prob_positive[i] > posterior_prob_negative[i]:\r\n",
        "            test_predict.append(\"1\")\r\n",
        "        else:\r\n",
        "            test_predict.append(\"0\")\r\n",
        "        \r\n",
        "    test_df['Predicted Sentiment'] = test_predict \r\n",
        "    accuracy = accuracy_metric(test_df['Sentiment'], test_df['Predicted Sentiment'])\r\n",
        "    accur_values.append(accuracy)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "folds = cross_validation(clean_data, 7)\r\n",
        "for fold in folds:\r\n",
        "    train_set = list(folds)\r\n",
        "    train_set.remove(fold)\r\n",
        "    train_set = sum(train_set, [])\r\n",
        "    test_set = list()\r\n",
        "    for row in fold:\r\n",
        "        row_copy = list(row)\r\n",
        "        test_set.append(row_copy)\r\n",
        "    Naive_Bayes(train_set, test_set)\r\n",
        "        \r\n",
        "accuracy = np.array(accur_values)\r\n",
        "print('\\nAccuracy')\r\n",
        "print(np.mean(accuracy),' +/- ',np.std(accuracy))\r\n",
        "accur_values\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy\n",
            "81.48893360160966  +/-  3.5052819698560054\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[82.3943661971831,\n",
              " 86.61971830985915,\n",
              " 83.80281690140845,\n",
              " 75.35211267605634,\n",
              " 83.80281690140845,\n",
              " 78.87323943661971,\n",
              " 79.5774647887324]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBbMad5yLfbv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}